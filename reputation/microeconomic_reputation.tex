\documentclass{article}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{hyperref}

\newtheorem{conclusion}{Conclusion}[section]

\title{Strategies and reputation - a microeconomic description of the Golem marketplace}
\author{Jan Betley\\ Golem Factory}

\begin{document}
\maketitle
\section{Introduction}
\subsection{Reader notes}

Every important statement is labelled as a \underline{Conclusion} - consider skimming through them if you're not interested in the reasoning.

This document is quite formal, but please don't expect clean, bulletproof implications only. The purpose of this document is to
present the topic and conclusions while maintaining resonable level of brievity.

\subsection{Abstract}
This document provides a simple microeconomic model of the Golem marketplace. 
Following questions are answered within the model:

\begin{itemize}
\item What do we exactly mean by the "reputation"?
\item What is the exact problem we hope to solve with the reputation mechanism?
\item What are the other, non-reputation approaches to the main problem?
\item How to measure the quality of our solutions? I.e. how to know if we succeeded?
\end{itemize}


The problem is approached from the highest point of view - no specific solutions are proposed, only general classes of solutions are discussed.
With an exception of a few details/examples this document describes just a "general" marketplace (replace "provider/requestor" with "seller/buyer").

\subsection{Definitions}

\textbf{Agent} - A decision-making entity (person, company, etc.).
\newline
\textbf{Utility} - The total happiness of an agent.
\newline
\textbf{Utility function $U$} - A function $U: StateOfTheWorld -> \mathbb{R}$, defined for a particular agent, that represents their utility in a given situation.
\newline
\textbf{Expected utility} - For every possible decision an agent can make ($D$) and every possible state of the world $w$, there is some probability $P: (D, w) \rightarrow [0, 1]$  that given decision will lead to the given state of the world.
Agents don't have the full knowledge about $P$, they know only some information $I$ and an estimation of $P$ based on this information: $P_I: (D, w) \rightarrow [0, 1]$. The expected utility $E: (I, U, D) -> \mathbb{R}$ is defined as follows:

\begin{equation}
E(I, U, D) = \sum_{w \in all\_possible\_world\_states}U(w) * P_I(D, w)
\end{equation}

We'll be also using a shorter notation, $E(I, U, D) = E_A(D)$ to describe "expected utility of the decision $D$, for agent A, who has information $I$ and utility function $U$".

In other words, for agent $A$ and decision $D$, $E_A(D)$ is "how happy agent $A$ expects to be if they do $D$".
\newline

\textbf{Golem} - The observable result of all the work done by the Golem Factory - the Golem protocol, available software, state of the market etc.
\newline

\subsection{Additional assumptions}

\begin{enumerate}
\item The Expected Utility Hypothesis\footnote{\href{https://en.wikipedia.org/wiki/Expected\_utility\_hypothesis}{https://en.wikipedia.org/wiki/Expected\_utility\_hypothesis}}: every agent tries to maximize their expected utility.

\item Every agent can costlessy access and analyze all of the publicly available information about Golem. Thanks to this assumption we can remove $I$ from the equations - we no longer
    care about "what agent knows", but only about "what really is". This is a major simplification that might not be a good approximation of the "real world" Golem market, but we
    accept it for the sake of the brevity of this document. Also "truth about Golem is known" is an ideal world we would like to live in.

\item The expected utility and money are interchangeable, that is - for every agent $A$ and a pair of decisions $(D_1, D_2): E_A(D_1) < E_A(D_2)$, there is an amount of money X that
    can be given to the agent so that $E_A(D_1) + U_A(X) = E_A(D_2)$. This way we can treat utilities as if they were money, and thus compare them between different agents.

\item Lets define the Golem Value as:

\begin{equation}
    V_G = \sum_{A \in all\_agents\_using\_Golem}E_A(USE\_GOLEM)
\end{equation}
(Note that - because of assumption 1 - $E_A(USE\_GOLEM)$ is always positive, decision "use Golem" is only made by agents who expect to profit from it).

We assume that maximization of $V_G$ is one of the goals of the Golem Factory - and from the point of view of this document, the only goal.
\end{enumerate}

\section{The "reputation" and its purpose}
\subsection{Notation}

We'll be using a bunch of different symbols, but they follow a clear common pattern, so please don't be frightened.

\begin{itemize}
\item $V_A(a)$ is the total value of the agreement $a$ from the POV of agent $A$. As per assumption 3, this is "utility expressed as money".\footnote{
I.e. $V_A(a) = X$ means "when agent $A$ takes part in the agreement $a$, their hapiness changes as if they were given $X$ money".}
\item $V_P(a)$/$V_R(a)$ are agreement values from the POV of (respectively) provider/requestor.
\item $V_{PN}(a)$/$V_{RN}(a)$ are nominal (i.e. negotiated) values of the agreement. They equal $V_P(a)$/$V_R(a)$ if neither side breached the agreement $a$.
\item $V_{AL}(a)$ is the value lost by agent $A$ because of the other side breaching the agreement $a$.
\item $V_{AG}(a)$ is the value gained by agent $A$ when they break the agreement $a$.
\item $V_{PL}$, $V_{RL}$, $V_{PG}$, $V_{RG}$ are $V_{AL}$/$V_{AG}$ from the POV of provider/requestor.
\item $C_A$ is the cost of the participation in the Golem market for agent $A$ that is not related to any particular agreement 
(e.g. the opportunity cost\footnote{\href{https://en.wikipedia.org/wiki/Opportunity\_cost}{https://en.wikipedia.org/wiki/Opportunity\_cost}} of the hardware offered on the market, 
or the cost of writing the requestor agent).
\end{itemize}

\subsection{Dissolving the Golem Value}

Utilizing the above notation, we can rewrite the $V_G$ equation as:

\begin{equation}
    V_G = \sum_{a \in all\_agreements}(V_P(a) + V_R(a)) - \sum_{A \in all\_agents\_using\_Golem}C_A
\end{equation}

The following equation and it's counterpart from the requestor POV are true by definition:

\begin{equation}
    V_P(a) = V_{PN}(a) + V_{PG}(a) - V_{PL}(a)
\end{equation}

By placing them in the previous equation, we get:

\begin{equation}
\begin{split}
    V_G = \sum_{a \in all\_agreements}(V_{PN}(a) + V_{PG}(a) - V_{PL}(a) + V_{RN}(a) + V_{RG}(a) - V_{RL}(a)) \\
            - \sum_{A \in all\_agents\_using\_Golem}C_A \\
\end{split}
\end{equation}
\begin{equation}
\begin{split}
    V_G = \sum_{a \in all\_agreements}(V_{PN}(a) + V_{PG}(a)) \\
          - \sum_{a \in all\_agreements}(V_{PL}(a)- V_{RG}(a)) \\
          - \sum_{a \in all\_agreements}(V_{RL}(a)- V_{PG}(a)) \\
          - \sum_{A \in all\_agents\_using\_Golem}C_A
\end{split}
\end{equation}

Important note here is that both $\sum_{a \in all\_agreements}(V_{PL}(a)- V_{RG}(a))$ and $\sum_{a \in all\_agreements}(V_{RL}(a)- V_{PG}(a))$ are positive: 
when someone breaks the agreement, the harm done to the victim is usually greater then the offenders gain\footnote{TODO: examples/proof/justification?}.
Let's thus define one more symbol:
\begin{itemize}
\item $V_L(a) = (V_{PL}(a)- V_{RG}(a)) + (V_{RL}(a)- V_{PG}(a))$ - the total value lost because of agents breaking the terms of agreement $a$.
\end{itemize}
and use it to rewrite the main equation one last time:

\begin{equation}
\begin{split}
    V_G = \sum_{a \in all\_agreements}(V_{PN}(a) + V_{RN}(a) - V_L(a)) \\
          - \sum_{A \in all\_agents\_using\_Golem}C_A
\end{split}
\end{equation}

This equation defines few general ways to increase the $V_G$:

\begin{enumerate}
\item Increase the number of agreements
\item Increase the average nominal value of the agreement (e.g. by providing additional capabilities, like internet connectivity or GPU access)
\item Decrease the average value lost because of breaches of the agreements ($V_L(a)$)
\item Decrease the cost of the participation in the Golem market (e.g. by creating better SDKs)
\end{enumerate}

Note that these ways interact with each other: e.g. if we improve 2 by implementing some features that will be hard to use, we'll also worsen 4.
Or: the better is the average nominal value of the agreement, the more agreements we'll expect to have.
Or - what is important from the POV of this document - if we implement complex safeguards against cheating, they might have negative impact on all the other points.

Keeping that in mind, the rest of the document is aimed at the third direction from the above list.

\subsection{Honest strategy}

Fo an agreement $a$ between agents $A_1$ and $A_2$ let's define the "dishonesty index" of agent $A_2$ as:

\begin{equation}
    D_{A_2}(a) = \frac{V_{A_1L}(a)}{V_{A_1N}(a)}
\end{equation}

 
That is: if $A_1$ received everything that was agreed, $D_{A_2}(a) = 0$. If all agreement-related costs of $A_1$ are covered, but they got nothing more, $D_{A_2}(a) = 1$.
If $A_1$ lost on the agreement, $D_{A_2} > 1$.\footnote{Values below 0 are also possible, e.g. paying more than agreed is also "against the agreement".}

The value of $V_{A_1L}(a)$ (so also the dishonesty index) depends on the decision made by agent $A_1$. 
In an usual case the "visible decision" will by caused by the algorithm implemented in the provider/requestor agent,
but this is just an effect of the agent's "real decision" about the implementation.\footnote{In an extreme case we can imagine 
a human operator who directly interacts with the Golem protocol. Or just imagine someone who turns off the currently rented hardware.}

The agent's core decision-making process is called a "strategy". The better agent fulfills their part of the agreements, the more "honest" is the strategy.
So, in other words: when agent $A$ signs an agreement $a$ with an agent using a dishonest strategy, the expected value of $V_{AL}(a)$ is high.
When the other side is fully honest, $V_{AL}(a) = 0$. 
Note that agent's intentions don't matter here - there's no difference if an agent breaks an agreement on purpose or accidentally.
 
Agent always tries to maximize their own utility (the "expected utility maximization" assumption), in other words: agent always selects the most profitable strategy.
Let's now paraphrase the third goal from the previous section as:

\begin{conclusion}

The final purpose of the reputation system on Golem is to make honest strategies more profitable than dishonest strategies.

\label{main purpose conclusion}
\end{conclusion}


\subsection{Non-reputation solutions}

Let's consider few directions towards the goal defined in the previous section:

\begin{itemize}
\item Make dishonest strategies not available at all, e.g. ensure that debit note acceptance forces payment.
\item Make dishonest strategies hard to implement, e.g. hide/obfuscate some important components of Golem.
\item Add some mechanics that directly penalize dishonesty, e.g. require deposits and confiscate them when dishonesty is proven.
\end{itemize}

It's important to note that - while they have the same purpose as the reputation - they have nothing else to do with anything we call the "reputation".

\begin{conclusion}
Golem Factory works on the reputation system because we believe it's the best way to achieve goal defined in Conclusion \ref{main purpose conclusion}.
\end{conclusion}

\subsection{Defining reputation}

$V_{whatever}$ is a determined, known value. When trading on the Golem market, some values are known from the start (e.g. $V_{AN}(a)$), 
and other only post factum (e.g. $V_{AL}(a)$, so also $V_A(a)$).
When making decisions under uncertainity, we're using expected values - they will be written as $E(...)$, e.g. $E(V_A(a))$.

Imagine an honest agent $A_1$ who considers signing an agreement $a$ with agent $A_2$. The decision algorithm can be rougly summarized as
\begin{enumerate}
\item Calculate the expected value of the decision \textbf{not} to sign the agreement, $E_{A_1}(\neg a)$
\item Calculate the expected value of the decision to sign the agreement $E_{A_1}(a)$.
    Using the eq. 8 we can express this value as a function of the nominal value of the agreement and the
    estimated dishonesty index: $E_{A_1}(a) = V_{A_1N}(a) - V_{A_1N}(a) * E(D_{A_2}(a))$
\item Sign the agreement if $E_{A_1}(a) > E_{A_1}(\neg a)$
\end{enumerate}

This leads us to a simple observation: the higher dishonesty we expect, the better $E_N$ we need to sign the agreement, and thus to:

\begin{conclusion}

"Reputation system" is an attempt to solve the problem defined in the conclusion \ref{main purpose conclusion} in the following way:

\begin{itemize}
    \item Make some additional information available to the market participants
    \item This information can be used to estimate the "dishonesty index" of an agent, and thus improves the accuracy of the total agreement value estimation
    \item The more accurate is the total agreement value estimation, the less profitable it is to trade with dishonest agents
    \item The less profitable it is to trade with dishonest agents, the fewer/worse agreements they have
    \item The fewer/worse agreements dishonest agents have, the less profitable are dishonest strategies
\end{itemize}

\end{conclusion}


\section{Summary \& discussion}

\subsection{Agreement value estimation}
The mechanics described in the last conclusion work only when we can estimate the total value of the agreement.
It's worth noting that such measure is useful also for other purposes, such as estimating the total income from a provider node,
or just determining if Golem is worth using at all.

\begin{conclusion}

Any reputation system requires a reasonable way of estimating the "expected dishonesty index" of an agent, 
or more generally - the total agreement value.

\label{agreement value estimation}
\end{conclusion}

\subsection{Optimal strategies}

Different agents have different utilities and thus different strategies. 
Also, the market changes because of agents leaving/entering it. We should not expect there to be a single best strategy,
rather a constant mix of strategies governed only by a single rule: as the time passes, profitable strategies become more common.

E.g. consider a market where the optimal strategy for the provider is to be less honest than the average market honesty.
We should expect the average honesty to fall, and if this is still true for the lower average honesty, our reputation system is in a death spiral towards
the zero-honesty of all providers. Note that this situation is hard to recover from: if all providers are equally dishonest, there's no incentive for requestors
to use the dishonesty-penalizing strategies, so there will never be any incentive for a provider to increase their honesty.

But this works also the other way. If at a given moment the optimal strategy is to be \textbf{more} honest than the average, 
we'll see the average honesty growing. In fact, that should be our exact goal, but the weaker version is enough:

\begin{conclusion}
Reputation will work only on a market where the honesty of the optimal strategy always exceeds some treshold.
\label{required honesty level}
\end{conclusion}

\subsection{Market balance}
How to ensure this condition from Conclusion \ref{required honesty level} is satisfied? The general answer is: by influencing supply/demand balance.

E.g. let's say we want to increase the average honesty of the requestors. There are two ways to do this:

\begin{itemize}
    \item By influencing the supply:
        \begin{enumerate}
            \item Add high-quality (e.g. cheap) dishonesty-penalizing providers to the market
            \item Requestors want to trade with the new providers, so they have an incentive to become more honest
            \item As the requestors' strategy has changed, the new balance will be preserved even after we remove the providers added in 1
        \end{enumerate}
    \item By influencing the demand:
        \begin{enumerate}
        \item Add high-quality (e.g. accepting high prices) honest requestors to the market.
        \item Providers prefere to trade with the new requestors, so:
            \begin{enumerate}
                \item They have an incentive to use honesty-based strategies.
                \item There are honest requestors available, so providers trade less with the dishonest requestors.
            \end{enumerate}
        \item Buying becomes more expensive for the dishonest requestors, so they have an incentive to become more honest.
        \item As the providers' strategy has changed (2.1), the new balance will be preserved even after we remove the requestors added in 1.
        \end{enumerate}
\end{itemize}

\begin{conclusion}
Condition described in Conclusion \ref{required honesty level} is not an emergent phenomenon we should expect to see only after providing
the informaion required for Conclusion \ref{agreement value estimation}. It must be actively shaped by the market interventions,
and will be always vulnerable to a sufficiently strong intervention against it.
\end{conclusion}

\subsection{Plan for the Golem Factory}

NOTE: this section should \textbf{not} be treated as something final, but rather as a feed for thoughts/discussions\footnote{
    Four elements of the reputation system are specified here. For a better grap of their purpose, consider following exercise:
    \begin{itemize}
        \item Imagine any working reputation system you know (e.g. stars on Amazon).
        \item Find their counterparts in this other system.
        \item Consider the consequences if they went missing.
    \end{itemize}
}.

\begin{enumerate}
    \item Implement a way to calculate the "expected total agreement value" (Conclusion \ref{agreement value estimation})
        \begin{enumerate}
            \item Gather and share relevant information about providers/requestors
            \item Implement some ways to estimate the total agreement value from the available information.
                Note that this might be a very rough estimation, e.g.:
                \begin{enumerate}
                    \item For the provider - "(When signing the agreement) I expect to be paid $X\%$ of the final invoice".
                    \item For the requestor - "I expect there is $X\%$ chance provider will break the agreement before finishing", 
                        or "I expect provider to have $X\%$ performance of the average provider with the same offer, doing the same task".
                \end{enumerate}
            \item Make this modular/clean enough - we should make it easy for the Golem market participants 
                to implement their own estimation methods, better suiting their needs, or utilizing other information they have access to.
        \end{enumerate}
    \item Implement the evaluation of the "expected total agreement value". The market balance will be changing, dishonest agents have an incentive
        to worsen the estimations - we must know if our reputation system is working well enough.
        \begin{enumerate}
            \item Spawn our own providers and requestors, make them estimate agreement values (using methods from the previous point).
            \item Gather data $(estimation\_method, estimated\_value, final\_value)$.
            \item Control the quality of the estimation methods, improve them when it degrades.
        \end{enumerate}
    \item Implement market strategies that reasonably utilize the calculated "expected total agreement value". 
        Example strategies:
        \begin{enumerate}
            \item For the provider - if I expect to be paid $X\%$ of the invoice, I multiply the offer price for this requestor by $\frac{1}{X}$
            \item For the requestor - if I expect there to be a $X\%$ chance the provider will break the agreement before finishing computations,
                I multiply their offer score by $1 - X$.
        \end{enumerate}
    \item Take care about the market balance, by maintaining artificial providers/requestors (Conclusion \ref{market balance}).
\end{enumerate}


\end{document}
